{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "424a7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import transformers\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "SAVE_DIR = \"\"  #= \"#/home/alta/summary/pm574/podcast_sum0/lib/trained_models\"\n",
    "MODEL_NAME = \"bart-baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a7d2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Model & Optimizer\n",
    "    bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "    bart = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, bart.parameters()), lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    bart_config = bart.model.config\n",
    "    print(bart)\n",
    "    print(bart_config)\n",
    "    if torch_device == 'cuda': bart.cuda()\n",
    "    print(\"#parameters:\", sum(p.numel() for p in bart.parameters() if p.requires_grad))\n",
    "    bart.train()\n",
    "\n",
    "    # Data\n",
    "    #podcasts = load_podcast_data(sets=-1) # -1 means set0,..,set9 (excluding 10)\n",
    "    load_podcasts = pd.read_pickle(\"bart_train_regex.pkl\")\n",
    "    train_podcasts = load_podcasts[:5000]\n",
    "    \n",
    "    #batcher = BartBatcher(bart_tokenizer, bart.model.config, podcasts, torch_device)\n",
    "\n",
    "    # Validation\n",
    "    val_podcasts = load_podcasts[5000:5500]\n",
    "    #val_batcher = BartBatcher(bart_tokenizer, bart.model.config, val_podcasts, torch_device)\n",
    "\n",
    "    # Criterion\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none') # This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    "\n",
    "    training_step  = 0\n",
    "    batch_size     = 1\n",
    "    gradient_accum = 2\n",
    "    valid_step     = 20000 # every a few hours on lapaz machine (1GPU - 1080Ti)\n",
    "    total_step     = 20000 * 1000\n",
    "    best_val_loss  = 99999999\n",
    "    random_seed    = 777\n",
    "    stop_counter   = 0\n",
    "\n",
    "    print(\"batch_size:\", batch_size)\n",
    "    print(\"training_step:\", training_step)\n",
    "    print(\"gradient_accum:\", gradient_accum)\n",
    "    print(\"total_step:\", total_step)\n",
    "    print(\"valid_step:\", valid_step)\n",
    "    print(\"random_seed:\", random_seed)\n",
    "\n",
    "    # Randomness\n",
    "    random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    # shuffle data\n",
    "    train_podcasts.sample(frac=1)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Multiple GPUs: {}\".format(torch.cuda.device_count()))\n",
    "        bart = nn.DataParallel(bart)\n",
    "\n",
    "    while training_step < total_step:\n",
    "        # get a batch\n",
    "        #input_ids, attention_mask, target_ids, target_attention_mask = batcher.get_a_batch(batch_size=batch_size)\n",
    "        encoded_inputs = bart_tokenizer.batch_encode_plus(train_podcasts['transcript'].tolist(), add_special_tokens=True, pad_to_max_length=True,\n",
    "            max_length= bart_config.max_position_embeddings, return_tensors='pt')\n",
    "        print(type(train_podcasts['transcript'].tolist()))\n",
    "        #input_ids = bart_tokenizer.tokenize(train_podcasts)\n",
    "        \n",
    "        #decoder_input_ids = bart_tokenizer.encode(input_ids, return_tensors='pt')\n",
    "        print(type(train_podcasts['episode_description'].tolist()))\n",
    "        \n",
    "        batch_encoded_targets = bart_tokenizer.encode_plus(train_podcasts['episode_description'].tolist(), add_special_tokens=True, pad_to_max_length=True,\n",
    "            max_length= bart_config.max_position_embeddings, return_tensors='pt')\n",
    "        \n",
    "        input_ids = encoded_inputs['input_ids']\n",
    "        #print(type(input_ids))\n",
    "        attention_mask = encoded_inputs['attention_mask']\n",
    "        decoder_input_ids = batch_encoded_targets['input_ids']\n",
    "        decoder_attention_mask = batch_encoded_targets['attention_mask']\n",
    "        \n",
    "        shifted_target_ids = torch.zeros(decoder_input_ids.shape, dtype=decoder_input_ids.dtype)\n",
    "        shifted_target_attention_mask = torch.zeros(decoder_attention_mask.shape, dtype=torch.float)\n",
    "        shifted_target_ids[:,:-1] = decoder_input_ids.clone().detach()[:,1:]\n",
    "        shifted_target_attention_mask[:,:-1] = decoder_attention_mask.clone().detach()[:,1:]\n",
    "        \n",
    "        \n",
    "        #shifted_target_ids, shifted_target_attention_mask = batcher.shifted_target_left(target_ids, target_attention_mask)\n",
    "        # BART forward\n",
    "        x = bart(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "        )\n",
    "        # x[0] # decoder output\n",
    "        # x[1] # encoder output\n",
    "        lm_logits = x[0]\n",
    "\n",
    "        loss = criterion(lm_logits.view(-1, bart_config.vocab_size), shifted_target_ids.view(-1))\n",
    "        shifted_target_attention_mask = shifted_target_attention_mask.view(-1)\n",
    "        loss = (loss * shifted_target_attention_mask).sum() / shifted_target_attention_mask.sum()\n",
    "        loss.backward()\n",
    "\n",
    "        if training_step % gradient_accum == 0:\n",
    "            adjust_lr(optimizer, training_step)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if training_step % 1 == 0:\n",
    "            print(\"[{}] step {}/{}: loss = {:.5f}\".format(str(datetime.now()), training_step, total_step, loss))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # if training_step % 5 == 0:\n",
    "        #     tgt_len = target_attention_mask[0].sum().item()\n",
    "        #     print(\"REF: {}\".format(bart_tokenizer.decode(shifted_target_ids[0,:tgt_len].cpu().numpy())))\n",
    "        #     print(\"HYP: {}\".format(bart_tokenizer.decode(torch.argmax(lm_logits[0,:tgt_len].cpu(), dim=-1).numpy())))\n",
    "\n",
    "        if training_step % valid_step == 0 and training_step > 5:\n",
    "            bart.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_loss = validation(bart, bart_config, val_podcasts, 1, 1)\n",
    "            print(\"Valid Loss = {:.5f}\".format(valid_loss))\n",
    "            bart.train()\n",
    "            if valid_loss < best_val_loss:\n",
    "                stop_counter = 0\n",
    "                best_val_loss = valid_loss\n",
    "                print(\"Model improved\".format(stop_counter))\n",
    "            else:\n",
    "                stop_counter += 1\n",
    "                print(\"Model not improved #{}\".format(stop_counter))\n",
    "                if stop_counter == 3:\n",
    "                    print(\"Stop training!\")\n",
    "                    return\n",
    "\n",
    "            state = {\n",
    "                'training_step': training_step,\n",
    "                'model': bart.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss\n",
    "            }\n",
    "            savepath = \"{}/{}-step{}.pt\".format(SAVE_DIR, MODEL_NAME, training_step)\n",
    "            torch.save(state, savepath)\n",
    "            print(\"Saved at {}\".format(savepath))\n",
    "\n",
    "        training_step += 1\n",
    "    print(\"Finish Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d7f1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adjust_lr(optimizer, step, warmup=10000):\n",
    "    \"\"\"to adjust the learning rate\"\"\"\n",
    "    step = step + 1 # plus 1 to avoid ZeroDivisionError\n",
    "    lr = 2e-3 * min(step**(-0.5), step*(warmup**(-1.5))) # 0.5 for effecetive batch_size\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a952acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(bart, bart_config, val_podcasts, epoch_counter, batch_size):\n",
    "    print(\"start validating\")\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "    sum_loss = 0\n",
    "    sum_token = 0\n",
    "    while epoch_counter < 1:\n",
    "        #input_ids, attention_mask, target_ids, target_attention_mask = val_batcher.get_a_batch(batch_size=batch_size)\n",
    "        #shifted_target_ids, shifted_target_attention_mask = val_batcher.shifted_target_left(target_ids, target_attention_mask)\n",
    "        \n",
    "        \n",
    "        encoded_inputs = bart_tokenizer.batch_encode_plus(val_podcasts['transcript'].tolist(), add_special_tokens=True, pad_to_max_length=True,\n",
    "            max_length= bart_config.max_position_embeddings, return_tensors='pt')\n",
    "        \n",
    "        #input_ids = bart_tokenizer.tokenize(train_podcasts)\n",
    "        input_ids = encoded_inputs['input_ids']\n",
    "        attention_mask = encoded_inputs['attention_mask']\n",
    "        decoder_input_ids = bart_tokenizer.encode(input_ids, return_tensors='pt')\n",
    "        \n",
    "        batch_encoded_targets = bart_tokenizer.encode(val_podcasts['episode_description'].tolist(),\n",
    "            add_special_tokens=True, pad_to_max_length=True,\n",
    "            max_length=144, return_tensors='pt')\n",
    "\n",
    "        target_ids = batch_encoded_targets['input_ids']\n",
    "        target_attention_mask = batch_encoded_targets['attention_mask']\n",
    "        \n",
    "        shifted_target_ids = torch.zeros(decoder_input_ids.shape, dtype=decoder_input_ids.dtype)\n",
    "        shifted_target_attention_mask = torch.zeros(decoder_attention_mask.shape, dtype=torch.float)\n",
    "        shifted_target_ids[:,:-1] = decoder_input_ids.clone().detach()[:,1:]\n",
    "        shifted_target_attention_mask[:,:-1] = decoder_attention_mask.clone().detach()[:,1:]\n",
    "        \n",
    "        x = bart(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=target_ids,\n",
    "            decoder_attention_mask=target_attention_mask,\n",
    "        )\n",
    "        lm_logits = x[0]\n",
    "        loss = criterion(lm_logits.view(-1, bart_config.vocab_size), shifted_target_ids.view(-1))\n",
    "        shifted_target_attention_mask = shifted_target_attention_mask.view(-1)\n",
    "        sum_loss += (loss * shifted_target_attention_mask).sum().item()\n",
    "        sum_token += shifted_target_attention_mask.sum().item()\n",
    "        print(\"#\", end=\"\")\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "    epoch_counter = 0\n",
    "    print(\"finish validating\")\n",
    "\n",
    "    return sum_loss / sum_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1244281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartForConditionalGeneration(\n",
      "  (model): BartModel(\n",
      "    (shared): Embedding(50264, 1024, padding_idx=1)\n",
      "    (encoder): BartEncoder(\n",
      "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
      "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): BartDecoder(\n",
      "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
      "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
      ")\n",
      "BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large-cnn\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "#parameters: 406290432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 1\n",
      "training_step: 0\n",
      "gradient_accum: 2\n",
      "total_step: 20000000\n",
      "valid_step: 20000\n",
      "random_seed: 777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anany\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c627f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_podcasts = pd.read_pickle(\"bart_train_regex.pkl\")\n",
    "train_podcasts = load_podcasts[:5000]\n",
    "\n",
    "lst = (train_podcasts['transcript'].tolist())\n",
    "ls2 = (train_podcasts['episode_description'].tolist())\n",
    "for i in range(len(lst)):\n",
    "    if type(lst[1]) != type(ls2[2]):\n",
    "        print(\"Yes\")\n",
    "    #print(type(lst[1]), type(ls2[2]) )\n",
    "#train_podcasts['episode_description'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89604949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000\n"
     ]
    }
   ],
   "source": [
    "print(len(lst), len(ls2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe8c7a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'torch.version' from 'C:\\\\Users\\\\anany\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\torch\\\\version.py'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module transformers has no attribute version",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21056/1265042790.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2141\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2142\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2143\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module transformers has no attribute version"
     ]
    }
   ],
   "source": [
    "print(torch.version)\n",
    "print(transformers.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331c19f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
